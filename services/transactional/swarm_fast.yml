version: "3"


##########################################################################################
#########################    DEPLOYMENT CONFIGS FOR NODES    #############################

x-common-restart-default: &common_restart_policy
  restart_policy:
    condition: on-failure

x-common-network: &common_network
  networks:
    - layer_fast_prod

x-common-deploy-master: &common_deploy_master
  <<: *common_network
  deploy:
    <<: *common_restart_policy
    placement:
      constraints: [node.hostname == dadaia-desktop]

x-common-deploy-worker-1: &common_deploy_worker_1
  <<: *common_network
  deploy:
    <<: *common_restart_policy
    placement:
      constraints: [node.hostname == dadaia-HP-ZBook-15-G2]

x-common-deploy-worker-2: &common_deploy_worker_2
  <<: *common_network
  deploy:
    <<: *common_restart_policy
    placement:
      constraints: [node.hostname == dadaia-server-2]

x-common-deploy-worker-3: &common_deploy_worker_3
  <<: *common_network
  deploy:
    <<: *common_restart_policy
    placement:
      constraints: [node.hostname == dadaia-server]

##########################################################################################
#####################    NETWORK AND KAFKA CONFIGS    ####################################

x-default-healthcheck: &default_healthcheck
  interval: 10s
  timeout: 10s
  retries: 3


x-kafka-common-configs: &kafka_common_configs
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
  KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
  KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  KAFKA_JMX_PORT: 9101
  KAFKA_JMX_HOSTNAME: localhost
  KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL}
  KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
  CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
  CONFLUENT_METRICS_ENABLE: 'true'
  CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
  KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

x-spark-worker-configs: &spark_worker_configs
  environment:
    - SPARK_MODE=worker
    - SPARK_MASTER_URL=spark://spark-master:7077
    - SPARK_WORKER_MEMORY=1G
    - SPARK_WORKER_CORES=1
    - SPARK_RPC_AUTHENTICATION_ENABLED=no
    - SPARK_RPC_ENCRYPTION_ENABLED=no
    - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    - SPARK_SSL_ENABLED=no
    - SPARK_USER=spark


##########################################################################################
#############################    SERVICES    #############################################

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    <<: *common_deploy_worker_1
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 3000
    volumes:
    - type: volume
      source: dm_cluster_prod_zookeeper_data
      target: /var/lib/zookeeper/data
    - type: volume
      source: dm_cluster_prod_zookeeper_log
      target: /var/lib/zookeeper/log
    - type: volume
      source: dm_cluster_prod_zookeeper_secrets
      target: /etc/zookeeper/secrets


  ################################################################################
  ######################    BEGIN KAFKA SERVICES    ##############################

  broker-1:
    image: confluentinc/cp-server:7.6.0
    hostname: broker-1
    <<: *common_deploy_worker_1
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-1:29092,PLAINTEXT_HOST://localhost:9092
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker-1:29092
      <<: *kafka_common_configs
    volumes:
    - type: volume
      source: dm_cluster_prod_kafka_1_data
      target: /var/lib/kafka/data
    - type: volume
      source: dm_cluster_prod_kafka_1_secrets
      target: /etc/kafka/secrets
    healthcheck:
      test: [ "CMD", "nc", "-z", "zookeeper", "2181" ]
      <<: *default_healthcheck


  broker-2:
    image: confluentinc/cp-server:7.6.0
    hostname: broker-2
    <<: *common_deploy_worker_2
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-2:29093,PLAINTEXT_HOST://localhost:9093
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker-2:29093
      <<: *kafka_common_configs
    volumes:
    - type: volume
      source: dm_cluster_prod_kafka_2_data
      target: /var/lib/kafka/data
    - type: volume
      source: dm_cluster_prod_kafka_2_secrets
      target: /etc/kafka/secrets
    healthcheck:
      test: [ "CMD", "nc", "-z", "zookeeper", "2181" ]
      <<: *default_healthcheck

  broker-3:
    image: confluentinc/cp-server:7.6.0
    hostname: broker-3
    <<: *common_deploy_worker_3
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-3:29094,PLAINTEXT_HOST://localhost:9094
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker-3:29094
      <<: *kafka_common_configs
    volumes:
    - type: volume
      source: dm_cluster_prod_kafka_3_data
      target: /var/lib/kafka/data
    - type: volume
      source: dm_cluster_prod_kafka_3_secrets
      target: /etc/kafka/secrets
    healthcheck:
      <<: *default_healthcheck
      test: [ "CMD", "nc", "-z", "zookeeper", "2181" ]
    

  schema-registry:
    image: confluentinc/cp-schema-registry:7.6.0
    hostname: schema-registry
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    <<: *common_deploy_worker_1
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker-1:29092,broker-2:29093,broker-3:29094'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: FULL


  connect:
    image: marcoaureliomenezes/labs-kafka-connect:1.0.0
    hostname: connect
    restart: on-failure
    <<: *common_deploy_worker_1
    networks:
      - layer_fast_prod
      - layer_batch_prod
    depends_on:
      - broker-1
      - broker-2
      - broker-3
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-1:29092,broker-2:29093,broker-3:29094'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.5.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR

  # KAFKA UI -> http://192.168.15.101:9021
  control-center:
    image: confluentinc/cp-enterprise-control-center:7.5.0
    hostname: control-center
    <<: *common_deploy_worker_1
    depends_on:
      - broker-1
      - broker-2
      - broker-3
      - schema-registry
      - connect
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker-1:29092,broker-2:29093,broker-3:29094'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

  ################################################################################
  ######################    BEGIN SPARK SERVICES    ##############################

  # SPARK UI -> http://192.168.15.101:18080
  spark-master:
    image: docker.io/bitnami/spark:3.5
    <<: *common_deploy_worker_1
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '18080:8080'

  spark-worker-1:
    image: docker.io/bitnami/spark:3.5
    <<: *common_deploy_worker_2
    <<: *spark_worker_configs
      

  spark-worker-2:
    image: docker.io/bitnami/spark:3.5
    <<: *common_deploy_worker_2
    <<: *spark_worker_configs


  spark-worker-3:
    image: docker.io/bitnami/spark:3.5
    <<: *common_deploy_worker_3
    <<: *spark_worker_configs

  ################################################################################
  ######################    BEGIN DATABASE SERVICES    ###########################

  scylladb:
    image: marcoaureliomenezes/dm-scylladb:1.0.0
    <<: *common_deploy_master
    restart: always
    ports:
      - "9042:9042"
    volumes:
      - 'dm_cluster_prod_scylladb_data:/var/lib/scylla'

  redis: 
    image: redis:7.2
    <<: *common_deploy_worker_2
    command: redis-server --requirepass secret
    ports:
      - "16379:6379"


  topics_creator:
    image: marcoaureliomenezes/dm-onchain-stream-txs:1.0.0
    entrypoint: "python -u 0_topics_creator.py configs/topics_prd.ini"
    env_file:
      - ../app/.secrets.conf
    environment:
      KAFKA_CLUSTER: 'broker-1:29092,broker-2:29093,broker-3:29094'
      NETWORK: mainnet
    depends_on:
      - broker-1
      - broker-2
      - broker-3
    <<: *common_deploy_master
      
volumes:
  dm_cluster_prod_zookeeper_data:
  dm_cluster_prod_zookeeper_log:
  dm_cluster_prod_zookeeper_secrets:
  dm_cluster_prod_kafka_1_data:
  dm_cluster_prod_kafka_1_secrets:
  dm_cluster_prod_kafka_2_data:
  dm_cluster_prod_kafka_2_secrets:
  dm_cluster_prod_kafka_3_data:
  dm_cluster_prod_kafka_3_secrets:
  dm_cluster_prod_scylladb_data:

networks:
  layer_fast_prod:
    external: true
  layer_batch_prod:
    external: true

version: '3'


x-common-log-config: &default_config
  networks:
    - layer-batch-prod
  logging:
    driver: "json-file"
    options:
      max-file: "5"
      max-size: "10m"

x-common-restart-default: &common_restart_policy
  restart_policy:
    condition: on-failure

x-common-deploy-master: &common_deploy_master
  deploy:
    <<: *common_restart_policy
    placement:
      constraints:
        - node.hostname == dadaia-desktop

x-common-deploy-worker-1: &common_deploy_worker_1
  deploy:
    <<: *common_restart_policy
    placement:
      constraints:
        - node.hostname == dadaia-HP-ZBook-15-G2

x-common-deploy-worker-2: &common_deploy_worker_2
  deploy:
    <<: *common_restart_policy
    placement:
      constraints:
        - node.hostname == dadaia-server

x-common-deploy-worker-3: &common_deploy_worker_3
  deploy:
    <<: *common_restart_policy
    placement:
      constraints:
        - node.hostname == dadaia-server-2

# ==============================================================
# =================  DEFINIÇÃO DOS SERVIÇOS  ===================
# ==============================================================
services:

  # APACHE HADOOP SERVICES
  namenode:
    image: marcoaureliomenezes/dm-hadoop-namenode:1.0.0
    <<: *default_config
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode_prod:/hadoop/dfs/name
    env_file:
      - ./hadoop.env
    
    environment:
      - CLUSTER_NAME=datalake
    <<: *common_deploy_master

  datanode:
    image: marcoaureliomenezes/dm-hadoop-datanode:1.0.0
    <<: *default_config
    ports:
      - 9864:9864
    volumes:
      - hadoop_datanode_prod_1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    <<: *common_deploy_master
    env_file:
      - ./hadoop.env

  resourcemanager:
    image: marcoaureliomenezes/dm-hadoop-resourcemanager:1.0.0
    <<: *default_config
    ports:
      - 18088:8088
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    <<: *common_deploy_master
    env_file:
      - ./hadoop.env

  nodemanager:
    image: marcoaureliomenezes/dm-hadoop-nodemanager:1.0.0
    <<: *default_config
    ports:
      - 18042:8042
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    <<: *common_deploy_master
    env_file:
      - ./hadoop.env

  historyserver:
    image: marcoaureliomenezes/dm-hadoop-historyserver:1.0.0
    <<: *default_config
    ports:
      - 19888:8188
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver_prod:/hadoop/yarn/timeline
    <<: *common_deploy_master
    env_file:
      - ./hadoop.env


  # APACHE HIVE SERVICES AND HUE
  hive-metastore:
    image: marcoaureliomenezes/dm-hive-base:1.0.0
    <<: *default_config
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 postgres:5432"
    ports:
      - "9083:9083"
    env_file:
      - ./hadoop-hive.env
    <<: *common_deploy_master


  hive-server:
    image: marcoaureliomenezes/dm-hive-server:1.0.0
    <<: *default_config
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://postgres:5432/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    env_file:
      - ./hadoop-hive.env
    <<: *common_deploy_master


  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    <<: *default_config
    deploy:
      <<: *common_restart_policy
      placement:
        constraints:
          - node.hostname == dadaia-HP-ZBook-15-G2

  postgres:
    image: marcoaureliomenezes/dm-postgres:1.0.0
    <<: *default_config
    volumes:
      - postgres_hive_hue_prod:/var/lib/postgresql/data
    <<: *common_deploy_master


  hue-webui:
    image: marcoaureliomenezes/dm-hue-webui:1.0.0
    <<: *default_config
    ports:
      - "32762:8888"
    volumes:
      - ../mnt/hue/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    environment:
      SERVICE_PRECONDITION: "hive-server:10000 postgres:5432"
    <<: *common_deploy_master


  # APACHE SPARK SERVICES
  spark-master:
    image: marcoaureliomenezes/dm-spark-master:1.0.0
    <<: *default_config
    ports:
      - "18080:8082"
    <<: *common_deploy_worker_3

  spark-worker:
    image: marcoaureliomenezes/dm-spark-worker:1.0.0
    <<: *default_config
    depends_on:
      - spark-master
    <<: *common_deploy_worker_3
      
      
  airflow:
    image: marcoaureliomenezes/dm-apache-airflow:1.0.0
    <<: *default_config
    volumes:
      - ../mnt/airflow/airflow.cfg:/opt/airflow/airflow.cfg
      - ../mnt/airflow/dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 8080:8080
    <<: *common_deploy_master

  postgres_airflow:
    image: postgres:11.4-alpine
    container_name: postgres_airflow
    <<: *default_config
    volumes:
      - postgres_airflow_prod:/var/lib/postgresql/data/pgdata
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow_db
      - PGDATA=/var/lib/postgresql/data/pgdata
    <<: *common_deploy_worker_2


  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - "8081:8080"
    stop_grace_period: 1m30s
    networks:
      - layer-batch-prod
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    <<: *common_deploy_worker_2

  # redis:
  #   image: redis:latest
  #   ports:
  #     - "6379:6379"
  #   networks:
  #     - hadoop-network
  #   <<: *default_deploy_node_4


  # redis-commander:
  #   image: rediscommander/redis-commander:latest
  #   environment:
  #     - REDIS_HOSTS=local:redis:6379
  #   ports:
  #     - "8082:8081"
  #   depends_on:
  #     - redis
  #   networks:
  #     - hadoop-network
  #   <<: *default_deploy_node_4

networks:
  layer-batch-prod:
    driver: overlay

volumes:
  hadoop_namenode_prod:
  hadoop_historyserver_prod:
  hadoop_datanode_prod_1:
  postgres_hive_hue_prod:
  postgres_airflow_prod:
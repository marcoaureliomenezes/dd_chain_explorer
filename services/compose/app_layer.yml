x-common-conf: &common_conf
  restart: on-failure
  networks:
    - ice_lakehouse_dev

x-conf-dev-onchain-stream-txs: &conf_dev_onchain_stream_txs
  build: ../../docker/app_layer/onchain-stream-txs
  volumes:
    - ../../docker/app_layer/onchain-stream-txs/src:/app
  <<: *common_conf

x-conf-dev-spark-job: &conf_dev_spark_streaming_job
  build: ../../docker/app_layer/spark-streaming-jobs
  volumes:
    - ../../docker/app_layer/spark-streaming-jobs/src:/app
    - ../../docker/app_layer/spark-streaming-jobs/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
  <<: *common_conf

services:

  ################################################################################################
  ############################    PYTHON APPLICATIONS    #########################################

  python-job-mined-blocks:
    <<: *conf_dev_onchain_stream_txs
    container_name: python-job-mined-blocks
    entrypoint: "python -u 1_mined_blocks_crawler.py configs/producers.ini"
    env_file:
      - ./conf/.secrets.conf
      - ./conf/kafka.conf
    environment:
      AKV_NODE_NAME: DataMasterNodeAsAService
      AKV_SECRET_NAME: 'alchemy-api-key-1'
      TOPIC_LOGS: mainnet.0.application.logs
      TOPIC_MINED_BLOCKS: mainnet.1.mined_blocks.data
      TOPIC_TXS_HASH_IDS: 'mainnet.3.mined.txs.hash_id'
      TOPIC_TXS_HASH_IDS_PARTITIONS: 8
      CLOCK_FREQUENCY: 1
      TXS_PER_BLOCK: 4


  python-job-orphan-blocks:
    <<: *conf_dev_onchain_stream_txs
    container_name: python-job-orphan-blocks
    entrypoint: "python -u 2_orphan_blocks_crawler.py configs/producers.ini configs/consumers.ini"
    env_file:
      - ./conf/.secrets.conf
      - ./conf/kafka.conf
      - ./conf/redis.conf
    environment:
      AKV_NODE_NAME: DataMasterNodeAsAService
      AKV_SECRET_NAME: 'alchemy-api-key-1'
      TOPIC_LOGS: mainnet.0.application.logs
      TOPIC_MINED_BLOCKS: mainnet.1.mined_blocks.data
      TOPIC_ORPHAN_BLOCKS: mainnet.2.orphan_blocks.data
      TOPIC_TXS_HASH_IDS: mainnet.3.mined.txs.hash_id
      CONSUMER_GROUP_ID: cg_orphan_blocks
      TOPIC_TXS_HASH_IDS_PARTITIONS: 8


  python-job-mined-txs:
    <<: *conf_dev_onchain_stream_txs
    container_name: python-job-mined-txs
    entrypoint: "python -u 3_mined_txs_crawler.py configs/producers.ini configs/consumers.ini"
    env_file:
      - ./conf/.secrets.conf
      - ./conf/redis.conf
      - ./conf/kafka.conf
    environment:
      AKV_NODE_NAME: DataMasterNodeAsAService
      AKV_SECRET_NAMES: 'infura-api-key-1-12'
      TOPIC_LOGS: mainnet.0.application.logs
      TOPIC_TXS_HASH_IDS: mainnet.3.mined.txs.hash_id
      TOPIC_TXS_RAW_DATA: mainnet.4.mined.txs.raw_data
      CONSUMER_GROUP: 'cg_mined_raw_txs'
    # deploy:
    #   replicas: 2

  python-job-redis-collector:
    <<: *conf_dev_onchain_stream_txs
    container_name: python-job-redis-collector
    env_file:
      - ./conf/.secrets.conf
      - ./conf/redis.conf
    entrypoint: "python -u n_semaphore_collect.py"
    environment:
      FREQUENCY: 0.5


  # txs_input_decoder:
  #   <<: *conf_dev_onchain_stream_txs
  #   container_name: txs_input_decoder
  #   entrypoint: "python -u 3_txs_input_decoder.py configs/producers.ini configs/consumers.ini"
  #   env_file:
  #     - ../../conf/.secrets.conf
  #     - ./conf/kafka.conf
  #     - ../../conf/job.3.txs.input.decoder.conf
  #   environment:
  #     AKV_SCAN_NAME: DMEtherscanAsAService
  #     AKV_NODE_NAME: DataMasterNodeAsAService
  #     AKV_NODE_SECRET_NAME: infura-api-key-16
  #     AKV_SCAN_SECRET_NAME: etherscan-api-key-2
  #     TOPIC_LOGS: mainnet.0.application.logs
  #     TOPIC_TXS_RAW_DATA: mainnet.4.mined.txs.raw_data
  #     TOPIC_TXS_INPUT_DECODED: mainnet.5.mined.txs.input_decoded
  #     KAFKA_CG_INPUT_DECODER: cg_txs_input_decoder

  ################################################################################################
  #############################    SPARK APPLICATIONS    #########################################

  spark-app-apk-comsumption:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-apk-comsumption
    entrypoint: "sh /app/1_api_key_monitor/entrypoint.sh"
    env_file:
      - ./conf/.secrets.conf
      - ./conf/kafka.conf
      - ./conf/redis.conf
      - ./conf/lakehouse.conf
    environment:
      TOPIC_LOGS: mainnet.0.application.logs
      CONSUMER_GROUP: cg_logs_processor
      STARTING_OFFSETS: earliest
      MAX_OFFSETS_PER_TRIGGER: 3000


  spark-app-multiplex-bronze:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-multiplex-bronze
    entrypoint: "sh /app/2_job_bronze_multiplex/entrypoint.sh"
    env_file:
      - ./conf/.secrets.conf
      - ./conf/lakehouse.conf
      - ./conf/kafka.conf
    environment:
      CONSUMER_GROUP: cg_bronze_1
      STARTING_OFFSETS: latest
      MAX_OFFSETS_PER_TRIGGER: 1000

  spark-app-silver-blocks:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-silver-blocks
    #entrypoint: "sh /app/3_job_silver_app/entrypoint.sh"
    env_file:
      - ./conf/.secrets.conf
      - ./conf/lakehouse.conf
      - ./conf/kafka.conf
    environment:
      CONSUMER_GROUP: cg_silver_1
      STARTING_OFFSETS: latest
      MAX_OFFSETS_PER_TRIGGER: 1000


networks:
  ice_lakehouse_dev:
    name: ice_lakehouse_dev
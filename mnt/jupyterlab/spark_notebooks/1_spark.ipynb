{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-66b1a90a-298f-4a4a-9437-86880320deb1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.1 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.95.0 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.17.178 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#utils;2.17.178 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.17.178 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.17.178 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.5.1 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      ":: resolution report :: resolve 1878ms :: artifacts dl 64ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.1 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.5.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.1 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.95.0 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.30 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   1   ||   23  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-66b1a90a-298f-4a4a-9437-86880320deb1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 23 already retrieved (0kB/33ms)\n",
      "24/10/01 03:03:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a0d34dbf6264:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>iceberg_hello_world</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7cdeb97d89d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.spark import get_spark_session\n",
    "import os\n",
    "\n",
    "spark = get_spark_session(\"iceberg_DDL\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+---------+-----------+---------------+------+---------------+-------------+-----+\n",
      "|topic_key|topic_value|kafka_partition|offset|kafka_timestamp|timestamptype|topic|\n",
      "+---------+-----------+---------------+------+---------------+-------------+-----+\n",
      "+---------+-----------+---------------+------+---------------+-------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[65 32 37 34 37 6...|[00 00 00 00 04 8...|              0|  3879|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[37 61 33 61 36 3...|[00 00 00 00 04 8...|              0|  3880|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[65 38 38 38 35 3...|[00 00 00 00 04 8...|              0|  3881|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[64 65 30 32 38 3...|[00 00 00 00 04 8...|              0|  3882|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[34 31 65 61 66 6...|[00 00 00 00 04 8...|              0|  3883|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[62 66 65 30 31 3...|[00 00 00 00 04 8...|              0|  3884|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[66 31 63 34 31 3...|[00 00 00 00 04 8...|              0|  3885|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[65 38 62 61 65 6...|[00 00 00 00 04 8...|              0|  3886|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[61 30 36 66 62 3...|[00 00 00 00 04 8...|              0|  3887|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[37 65 38 36 36 3...|[00 00 00 00 04 8...|              0|  3888|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[61 33 33 62 66 6...|[00 00 00 00 04 8...|              0|  3889|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[31 64 63 33 39 6...|[00 00 00 00 04 8...|              0|  3890|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[31 62 30 35 35 6...|[00 00 00 00 04 8...|              0|  3891|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[37 34 64 37 33 3...|[00 00 00 00 04 8...|              0|  3892|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[36 33 30 32 37 3...|[00 00 00 00 04 8...|              0|  3893|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[37 38 35 38 39 6...|[00 00 00 00 04 8...|              0|  3894|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[39 32 38 31 34 3...|[00 00 00 00 04 8...|              0|  3895|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[66 32 30 66 33 3...|[00 00 00 00 04 8...|              0|  3896|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[61 32 65 39 30 3...|[00 00 00 00 04 8...|              0|  3897|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "|[38 65 34 64 33 6...|[00 00 00 00 04 8...|              0|  3898|2024-10-01 03:03:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[33 39 32 36 65 3...|[00 00 00 00 04 8...|              0|  3910|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[64 32 33 31 66 3...|[00 00 00 00 04 8...|              0|  3911|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[36 62 35 34 31 3...|[00 00 00 00 04 8...|              0|  3912|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[36 39 66 36 63 6...|[00 00 00 00 04 8...|              0|  3913|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[30 62 34 38 62 3...|[00 00 00 00 04 8...|              0|  3914|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[34 36 64 37 33 3...|[00 00 00 00 04 8...|              0|  3915|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[62 31 65 38 31 6...|[00 00 00 00 04 8...|              0|  3916|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[31 63 33 31 65 3...|[00 00 00 00 04 8...|              0|  3917|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[35 31 37 62 63 3...|[00 00 00 00 04 8...|              0|  3918|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[32 39 34 38 35 3...|[00 00 00 00 04 8...|              0|  3919|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[61 31 32 65 64 3...|[00 00 00 00 04 8...|              0|  3920|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[34 63 39 31 63 3...|[00 00 00 00 04 8...|              0|  3921|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[64 33 66 35 36 6...|[00 00 00 00 04 8...|              0|  3922|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[62 38 30 35 32 6...|[00 00 00 00 04 8...|              0|  3923|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[39 32 38 39 31 6...|[00 00 00 00 04 8...|              0|  3924|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[32 30 38 36 37 3...|[00 00 00 00 02 F...|              0|   199|2024-10-01 03:04:...|            0|mainnet.mined.blo...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[38 33 30 36 61 3...|[00 00 00 00 04 8...|              0|  3925|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[31 62 34 31 30 6...|[00 00 00 00 04 8...|              0|  3926|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[32 30 38 36 37 3...|[00 00 00 00 02 F...|              0|   200|2024-10-01 03:04:...|            0|mainnet.mined.blo...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[36 30 31 65 33 3...|[00 00 00 00 04 8...|              0|  3927|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[30 64 32 34 64 3...|[00 00 00 00 04 8...|              0|  3928|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[32 35 62 65 31 3...|[00 00 00 00 04 8...|              0|  3929|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[64 31 32 36 36 3...|[00 00 00 00 04 8...|              0|  3930|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 7\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[30 36 35 39 33 6...|[00 00 00 00 04 8...|              0|  3931|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 8\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[38 35 64 34 36 3...|[00 00 00 00 04 8...|              0|  3932|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 9\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[34 65 61 33 66 3...|[00 00 00 00 04 8...|              0|  3933|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[63 32 31 63 37 3...|[00 00 00 00 04 8...|              0|  3934|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[38 30 62 30 62 6...|[00 00 00 00 04 8...|              0|  3935|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[37 64 66 34 32 3...|[00 00 00 00 04 8...|              0|  3936|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[66 37 30 65 36 6...|[00 00 00 00 04 8...|              0|  3937|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 10\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[33 63 37 36 38 3...|[00 00 00 00 04 8...|              0|  3938|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 11\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[32 30 38 36 37 3...|[00 00 00 00 02 F...|              0|   201|2024-10-01 03:04:...|            0|mainnet.mined.blo...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/bitnami/python/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/bitnami/python/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/bitnami/python/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 12\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[39 33 33 66 61 3...|[00 00 00 00 04 8...|              0|  3939|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[66 33 66 66 33 3...|[00 00 00 00 04 8...|              0|  3940|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[33 34 66 64 35 3...|[00 00 00 00 04 8...|              0|  3941|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[36 66 39 65 30 6...|[00 00 00 00 04 8...|              0|  3942|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 13\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[34 37 34 65 35 3...|[00 00 00 00 04 8...|              0|  3943|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[62 34 38 31 65 3...|[00 00 00 00 04 8...|              0|  3944|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[62 32 39 37 36 6...|[00 00 00 00 04 8...|              0|  3945|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[65 64 37 33 64 3...|[00 00 00 00 04 8...|              0|  3946|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[31 65 63 39 37 3...|[00 00 00 00 04 8...|              0|  3947|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m data_transformed \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mtransform_data(data_extracted)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#query = engine.load_data_to_bronze(data_transformed)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_to_console\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m query\u001b[38;5;241m.\u001b[39mawaitTermination()\n",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m, in \u001b[0;36mAPIKeyMonitor.load_data_to_console\u001b[0;34m(self, df_transformed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_to_console\u001b[39m(\u001b[38;5;28mself\u001b[39m, df_transformed):\n\u001b[1;32m     39\u001b[0m   write_stream_query \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     40\u001b[0m     \u001b[43mdf_transformed\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteStream\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputMode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconsole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 45\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m   )\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m write_stream_query\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/streaming/query.py:221\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.11/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 14\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[65 39 65 63 33 3...|[00 00 00 00 04 8...|              0|  3948|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[37 64 39 61 64 3...|[00 00 00 00 04 8...|              0|  3949|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 15\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[62 30 32 64 36 6...|[00 00 00 00 04 8...|              0|  3950|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[30 35 31 37 63 3...|[00 00 00 00 04 8...|              0|  3951|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[39 39 61 62 30 3...|[00 00 00 00 04 8...|              0|  3952|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[39 34 30 65 62 6...|[00 00 00 00 04 8...|              0|  3953|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[62 39 61 64 39 3...|[00 00 00 00 04 8...|              0|  3954|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[31 30 37 38 37 3...|[00 00 00 00 04 8...|              0|  3955|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 16\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[65 35 64 64 65 3...|[00 00 00 00 04 8...|              0|  3956|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[34 37 39 30 63 3...|[00 00 00 00 04 8...|              0|  3957|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[31 65 65 63 37 6...|[00 00 00 00 04 8...|              0|  3958|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[64 65 61 31 61 6...|[00 00 00 00 04 8...|              0|  3959|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[35 35 39 38 36 3...|[00 00 00 00 04 8...|              0|  3960|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 17\n",
      "-------------------------------------------\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|           topic_key|         topic_value|kafka_partition|offset|     kafka_timestamp|timestamptype|               topic|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "|[62 39 30 32 34 3...|[00 00 00 00 04 8...|              0|  3961|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[36 62 66 31 37 6...|[00 00 00 00 04 8...|              0|  3962|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[30 64 31 62 33 3...|[00 00 00 00 04 8...|              0|  3963|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "|[66 33 38 36 38 3...|[00 00 00 00 04 8...|              0|  3964|2024-10-01 03:04:...|            0|mainnet.mined.txs...|\n",
      "+--------------------+--------------------+---------------+------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql.functions import col, expr, split, window, count, max\n",
    "from pyspark.sql.avro.functions import from_avro\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "from utils.schema_registry_utils import SchemaRegistryUtils\n",
    "\n",
    "class APIKeyMonitor:\n",
    "   \n",
    "  def __init__(self, spark, kafka_options):\n",
    "    self.spark = spark\n",
    "    self.kafka_options = kafka_options\n",
    "\n",
    "\n",
    "  def extract_data(self, avro_schema: str):\n",
    "    df_simple_transactions = (\n",
    "      self.spark\n",
    "        .readStream\n",
    "        .format(\"kafka\")\n",
    "        .options(**self.kafka_options)\n",
    "        .load()\n",
    "        .withColumn(\"offset\", col(\"offset\").cast(IntegerType()))\n",
    "        .withColumn(\"timestamp\", col(\"timestamp\").cast(StringType()))\n",
    "        .withColumnRenamed(\"key\", \"topic_key\")\n",
    "        .withColumnRenamed(\"value\", \"topic_value\")\n",
    "        .withColumnRenamed(\"timestamp\", \"kafka_timestamp\")\n",
    "        .withColumnRenamed(\"partition\", \"kafka_partition\")\n",
    "        .select(\"topic_key\", \"topic_value\",  \"kafka_partition\", \"offset\",\n",
    "                \"kafka_timestamp\", \"timestamptype\", \"topic\"))\n",
    "    return df_simple_transactions\n",
    "\n",
    "\n",
    "  def transform_data(self, df_stream):\n",
    "    return df_stream\n",
    "\n",
    "\n",
    "  def load_data_to_console(self, df_transformed):\n",
    "    write_stream_query = (\n",
    "      df_transformed\n",
    "        .writeStream\n",
    "        .outputMode(\"append\")\n",
    "        .format(\"console\")\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    )\n",
    "    return write_stream_query\n",
    "\n",
    "  def load_data_to_bronze(self, df_transformed):\n",
    "    query = (\n",
    "      df_transformed\n",
    "        .writeStream\n",
    "        .format(\"iceberg\")\n",
    "        .outputMode(\"append\")\n",
    "        .option(\"checkpointLocation\", \"hdfs://namenode:9000/dm_lakehouse/checkpoint/all_topics\")\n",
    "        .toTable(\"bronze_fast.all_topics\")\n",
    "    )\n",
    "    return query\n",
    "\n",
    "\n",
    "APP_NAME = \"Handle_Simple_Transactions\"\n",
    "SPARK_URL = os.getenv(\"SPARK_MASTER_URL\")\n",
    "\n",
    "KAFKA_CLUSTER = os.getenv(\"KAFKA_BROKERS\", \"broker:29092\")\n",
    "CONSUMER_GROUP = os.getenv(\"CG_API_KEY_CONSUME\", \"cg_war\")\n",
    "STARTING_OFFSETS = os.getenv(\"STARTING_OFFSETS\", \"latest\")\n",
    "MAX_OFFSETS_PER_TRIGGER = os.getenv(\"MAX_OFFSETS_PER_TRIGGER\", 1000)\n",
    "\n",
    "SCHEMA_REGISTRY_URL = \"http://schema-registry:8081\"\n",
    "SCHEMA_REGISTRY_SUBJECT = \"mainnet.application.logs-value\"\n",
    "\n",
    "kafka_options = {\n",
    "\"kafka.bootstrap.servers\": KAFKA_CLUSTER,\n",
    "\"subscribe\": \"mainnet.mined.block.metadata,mainnet.mined.txs.token.transfer\",\n",
    "\"startingOffsets\": STARTING_OFFSETS,\n",
    "\"group.id\": CONSUMER_GROUP,\n",
    "\"maxOffsetsPerTrigger\": MAX_OFFSETS_PER_TRIGGER \n",
    "}\n",
    "\n",
    "engine = APIKeyMonitor(spark, kafka_options)\n",
    "sc_client = SchemaRegistryUtils.get_schema_registry_client(SCHEMA_REGISTRY_URL)\n",
    "avro_schema_logs = SchemaRegistryUtils.get_avro_schema(sc_client, SCHEMA_REGISTRY_SUBJECT)\n",
    "\n",
    "data_extracted = engine.extract_data(avro_schema_logs)\n",
    "data_transformed = engine.transform_data(data_extracted)\n",
    "#query = engine.load_data_to_bronze(data_transformed)\n",
    "query = engine.load_data_to_console(data_transformed)\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/01 03:04:37 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 18, writer: ConsoleWriter[numRows=20, truncate=true]] is aborting.\n",
      "24/10/01 03:04:37 ERROR WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 18, writer: ConsoleWriter[numRows=20, truncate=true]] aborted.\n",
      "24/10/01 03:04:37 ERROR MicroBatchExecution: Query [id = 8a456d78-f365-4abb-97ec-58a71b0fc516, runId = 260702d8-ad4d-411b-af8c-fd946a37f224] terminated with error\n",
      "java.lang.IllegalStateException: SparkContext has been shutdown\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2390)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:307)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:318)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4332)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3573)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:741)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Exception in thread \"stream execution thread for [id = 8a456d78-f365-4abb-97ec-58a71b0fc516, runId = 260702d8-ad4d-411b-af8c-fd946a37f224]\" org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef.deactivateInstances(StateStoreCoordinator.scala:119)\n",
      "\tat org.apache.spark.sql.streaming.StreamingQueryManager.notifyQueryTermination(StreamingQueryManager.scala:426)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$3(StreamExecution.scala:360)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:340)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:100)\n",
      "\t... 11 more\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

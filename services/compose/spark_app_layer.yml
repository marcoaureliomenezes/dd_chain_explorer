x-conf-dev-spark-job: &conf_dev_spark_streaming_job
  restart: on-failure
  networks:
    - vpc_kafka
  build: ../../docker/app_layer/spark-streaming-jobs
  volumes:
    - ../../docker/app_layer/spark-streaming-jobs/src:/app
    - ../../docker/app_layer/spark-streaming-jobs/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf

services:

  spark-app-apk-comsumption:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-apk-comsumption
    entrypoint: "sh /app/1_api_key_monitor/entrypoint.sh"
    env_file:
      - ./conf/dev.secrets.conf
      - ./conf/dev.kafka.conf
      - ./conf/dev.redis.conf
      - ./conf/dev.lakehouse.conf
    environment:
      TOPIC_LOGS: mainnet.0.application.logs
      CONSUMER_GROUP: cg_logs_processor
      STARTING_OFFSETS: earliest
      MAX_OFFSETS_PER_TRIGGER: 3000


  spark-app-multiplex-bronze:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-multiplex-bronze
    entrypoint: "sh /app/2_job_bronze_multiplex/entrypoint.sh"
    env_file:
      - ./conf/swarm.secrets.conf
      - ./conf/dev.kafka.conf
      - ./conf/dev.lakehouse.conf
    environment:
      CONSUMER_GROUP: cg_bronze_1
      STARTING_OFFSETS: earliest
      MAX_OFFSETS_PER_TRIGGER: 1000

  spark-app-silver-blocks:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-silver-blocks
    entrypoint: "sh /app/3_job_silver_blocks/entrypoint.sh"
    env_file:
      - ./conf/swarm.secrets.conf
      - ./conf/dev.kafka.conf
      - ./conf/dev.lakehouse.conf


  spark-app-silver-txs:
    <<: *conf_dev_spark_streaming_job
    container_name: spark-app-silver-txs
    entrypoint: "sh /app/4_job_silver_transactions/entrypoint.sh"
    env_file:
      - ./conf/swarm.secrets.conf
      - ./conf/dev.kafka.conf
      - ./conf/dev.lakehouse.conf


networks:
  vpc_kafka:
    external: true
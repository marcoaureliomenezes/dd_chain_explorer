x-common-log-config: &default_config
  restart: always
  networks:
    - analytical_layer
  logging:
    driver: "json-file"
    options:
      max-file: "5"
      max-size: "10m"


x-common-healthcheck-default: &default_healthcheck
  timeout: 45s
  interval: 10s
  retries: 10
  start_period: 10s

####################################################################################################
####################################################################################################

x-conf-dev-spark-job: &conf_dev_spark_job
  build: ../../docker/app_layer/spark-batch-jobs
  volumes:
    - ../../docker/app_layer/spark-batch-jobs/src:/app
  <<: *default_config

####################################################################################################
##############################    DEFINIÇÃO DOS SERVIÇOS    ########################################
####################################################################################################

services:

  namenode:
    build: ../../docker/customized/hadoop/namenode
    container_name: namenode
    <<: *default_config
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode_dev_vol:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=dd_chain_explorer_dev
    env_file:
      - ./conf/hadoop_env_vars.conf

  datanode:
    build: ../../docker/customized/hadoop/datanode
    container_name: datanode
    <<: *default_config
    volumes:
      - hadoop_datanode_dev_vol:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./conf/hadoop_env_vars.conf
  ####################################################################################################
  ###################################   YARN SERVICES    #############################################
  # resourcemanager:
  #   build: ../../docker/customized/hadoop/resourcemanager
  #   container_name: resourcemanager
  #   <<: *default_config
  #   ports:
  #     - 8088:8088
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
  #   env_file:
  #     - ./conf/hadoop.env
  # nodemanager:
  #   build: ../../docker/customized/hadoop/nodemanager
  #   container_name: nodemanager
  #   <<: *default_config
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
  #   env_file:
  #     - ./conf/hadoop.env
  # historyserver:
  #   build: ../../docker/customized/hadoop/historyserver
  #   container_name: historyserver
  #   <<: *default_config
  #   ports:
  #     - 8188:8188
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
  #   volumes:
  #     - hadoop_historyserver_dev_vol:/hadoop/yarn/timeline
  #   env_file:
  #     - ./conf/hadoop.env
  #
  ####################################################################################################
  ###############################   HIVE SERVICES AND HUE    #########################################

  postgres_hive:
    build: ../../docker/customized/postgres/
    container_name: postgres_hive
    environment:
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
      POSTGRES_DB: metastore_db
    volumes:
      - pg_lakehouse_dev_vol:/var/lib/postgresql/data
    <<: *default_config

  metastore:
    build: ../../docker/customized/hive/
    container_name: metastore
    ports:
      - "9083:9083"
    <<: *default_config
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver 
                     -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres_hive:5432/metastore_db 
                     -Djavax.jdo.option.ConnectionUserName=hive
                     -Djavax.jdo.option.ConnectionPassword=hive"
    depends_on:
      - postgres_hive
      
  hive-server:
    build: ../../docker/customized/hive/
    container_name: hive-server
    <<: *default_config
    ports:
      - "10000:10000"
      - "10002:10002"
    environment:
      SERVICE_NAME: hiveserver2
      SERVICE_OPTS: "-Dhive.metastore.uris=thrift://metastore:9083"
      IS_RESUME: "true"
    depends_on:
      - metastore

  hue:
    build: ../../docker/customized/hue/
    container_name: hue-webui
    ports:
      - "32762:8888"
    <<: *default_config
    volumes:
      - ../../mnt/hue/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    environment:
      SERVICE_PRECONDITION: "hive-server:10000 postgres_hive:5432"
    healthcheck:
      test: [ "CMD", "nc", "-z", "hue-webui", "8888" ]
      <<: *default_healthcheck

  ################################################################################################################
  #####################################    SPARK SERVICES    #####################################################

  spark-master:
    build: ../../docker/customized/spark
    container_name: spark-master
    <<: *default_config
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_METRICS_MASTER_ENABLED=true
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '18080:8080'
    healthcheck:
      test: [ "CMD", "ls" ]
      <<: *default_healthcheck

  spark-worker:
    build: ../../docker/customized/spark
    <<: *default_config
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=4
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    healthcheck:
      test: [ "CMD", "ls" ]
      <<: *default_healthcheck


  job_batch_1:
    build: ../../docker/app_layer/onchain-batch-txs
    env_file:
      - ./conf/.secrets.conf
    container_name: job_batch_1
    <<: *default_config
    environment:
      SERVICE_PRECONDITION: "spark-master:8080 spark-worker:8081"
    volumes:
      - ../../docker/app_layer/onchain-batch-txs/src:/app


volumes:
  hadoop_namenode_dev_vol:
  hadoop_datanode_dev_vol:
  hadoop_historyserver_dev_vol:
  pg_lakehouse_dev_vol:


networks:
  analytical_layer:
    name: analytical_layer

  dm_cluster_dev_fast:
    name: dm_cluster_dev_fast